{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Multi-factor Model\n",
    "## Instructions\n",
    "Each problem consists of a function to implement and instructions on how to implement the function.  The parts of the function that need to be implemented are marked with a `# TODO` comment. After implementing the function, run the cell to test it against the unit tests we've provided. For each problem, we provide one or more unit tests from our `project_tests` package. These unit tests won't tell you if your answer is correct, but will warn you of any major errors. Your code will be checked for the correct solution when you submit it to Udacity.\n",
    "\n",
    "## Packages\n",
    "When you implement the functions, you'll only need to you use the packages you've used in the classroom, like [Pandas](https://pandas.pydata.org/) and [Numpy](http://www.numpy.org/). These packages will be imported for you. We recommend you don't add any import statements, otherwise the grader might not be able to run your code.\n",
    "\n",
    "The other packages that we're importing are `project_helper` and `project_tests`. These are custom packages built to help you solve the problems.  The `project_helper` module contains utility functions and graph functions. The `project_tests` contains the unit tests for all the problems.\n",
    "\n",
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import project_tests\n",
    "import project_helper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Bundle\n",
    "We'll be using Zipline to handle our data. We've created a end of day data bundle for this project. Run the cell below to register this data bundle in zipline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import project_helper\n",
    "from zipline.data import bundles\n",
    "\n",
    "os.environ['ZIPLINE_ROOT'] = os.path.join(os.getcwd(), '..', '..', 'data', 'project_4_eod')\n",
    "\n",
    "ingest_func = bundles.csvdir.csvdir_equities(['daily'], project_helper.EOD_BUNDLE_NAME)\n",
    "bundles.register(project_helper.EOD_BUNDLE_NAME, ingest_func)\n",
    "\n",
    "print('Data Registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module os:\n",
      "\n",
      "NAME\n",
      "    os - OS routines for NT or Posix depending on what system we're on.\n",
      "\n",
      "MODULE REFERENCE\n",
      "    https://docs.python.org/3.7/library/os\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    This exports:\n",
      "      - all functions from posix or nt, e.g. unlink, stat, etc.\n",
      "      - os.path is either posixpath or ntpath\n",
      "      - os.name is either 'posix' or 'nt'\n",
      "      - os.curdir is a string representing the current directory (always '.')\n",
      "      - os.pardir is a string representing the parent directory (always '..')\n",
      "      - os.sep is the (or a most common) pathname separator ('/' or '\\\\')\n",
      "      - os.extsep is the extension separator (always '.')\n",
      "      - os.altsep is the alternate pathname separator (None or '/')\n",
      "      - os.pathsep is the component separator used in $PATH etc\n",
      "      - os.linesep is the line separator in text files ('\\r' or '\\n' or '\\r\\n')\n",
      "      - os.defpath is the default search path for executables\n",
      "      - os.devnull is the file path of the null device ('/dev/null', etc.)\n",
      "    \n",
      "    Programs that import and use 'os' stand a better chance of being\n",
      "    portable between different platforms.  Of course, they must then\n",
      "    only use functions that are defined by all platforms (e.g., unlink\n",
      "    and opendir), and leave all pathname manipulation to os.path\n",
      "    (e.g., split and join).\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        builtins.OSError\n",
      "    builtins.object\n",
      "        posix.DirEntry\n",
      "    builtins.tuple(builtins.object)\n",
      "        stat_result\n",
      "        statvfs_result\n",
      "        terminal_size\n",
      "        posix.times_result\n",
      "        posix.uname_result\n",
      "    \n",
      "    class DirEntry(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __fspath__(self, /)\n",
      "     |      Returns the path for the entry.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  inode(self, /)\n",
      "     |      Return inode of the entry; cached per entry.\n",
      "     |  \n",
      "     |  is_dir(self, /, *, follow_symlinks=True)\n",
      "     |      Return True if the entry is a directory; cached per entry.\n",
      "     |  \n",
      "     |  is_file(self, /, *, follow_symlinks=True)\n",
      "     |      Return True if the entry is a file; cached per entry.\n",
      "     |  \n",
      "     |  is_symlink(self, /)\n",
      "     |      Return True if the entry is a symbolic link; cached per entry.\n",
      "     |  \n",
      "     |  stat(self, /, *, follow_symlinks=True)\n",
      "     |      Return stat_result object for the entry; cached per entry.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |      the entry's base filename, relative to scandir() \"path\" argument\n",
      "     |  \n",
      "     |  path\n",
      "     |      the entry's full path name; equivalent to os.path.join(scandir_path, entry.name)\n",
      "    \n",
      "    error = class OSError(Exception)\n",
      "     |  Base class for I/O related errors.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OSError\n",
      "     |      Exception\n",
      "     |      BaseException\n",
      "     |      object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  characters_written\n",
      "     |  \n",
      "     |  errno\n",
      "     |      POSIX exception code\n",
      "     |  \n",
      "     |  filename\n",
      "     |      exception filename\n",
      "     |  \n",
      "     |  filename2\n",
      "     |      second exception filename\n",
      "     |  \n",
      "     |  strerror\n",
      "     |      exception strerror\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class stat_result(builtins.tuple)\n",
      "     |  stat_result(iterable=(), /)\n",
      "     |  \n",
      "     |  stat_result: Result from stat, fstat, or lstat.\n",
      "     |  \n",
      "     |  This object may be accessed either as a tuple of\n",
      "     |    (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime)\n",
      "     |  or via the attributes st_mode, st_ino, st_dev, st_nlink, st_uid, and so on.\n",
      "     |  \n",
      "     |  Posix/windows: If your platform supports st_blksize, st_blocks, st_rdev,\n",
      "     |  or st_flags, they are available as attributes only.\n",
      "     |  \n",
      "     |  See os.stat for more information.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      stat_result\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  st_atime\n",
      "     |      time of last access\n",
      "     |  \n",
      "     |  st_atime_ns\n",
      "     |      time of last access in nanoseconds\n",
      "     |  \n",
      "     |  st_birthtime\n",
      "     |      time of creation\n",
      "     |  \n",
      "     |  st_blksize\n",
      "     |      blocksize for filesystem I/O\n",
      "     |  \n",
      "     |  st_blocks\n",
      "     |      number of blocks allocated\n",
      "     |  \n",
      "     |  st_ctime\n",
      "     |      time of last change\n",
      "     |  \n",
      "     |  st_ctime_ns\n",
      "     |      time of last change in nanoseconds\n",
      "     |  \n",
      "     |  st_dev\n",
      "     |      device\n",
      "     |  \n",
      "     |  st_flags\n",
      "     |      user defined flags for file\n",
      "     |  \n",
      "     |  st_gen\n",
      "     |      generation number\n",
      "     |  \n",
      "     |  st_gid\n",
      "     |      group ID of owner\n",
      "     |  \n",
      "     |  st_ino\n",
      "     |      inode\n",
      "     |  \n",
      "     |  st_mode\n",
      "     |      protection bits\n",
      "     |  \n",
      "     |  st_mtime\n",
      "     |      time of last modification\n",
      "     |  \n",
      "     |  st_mtime_ns\n",
      "     |      time of last modification in nanoseconds\n",
      "     |  \n",
      "     |  st_nlink\n",
      "     |      number of hard links\n",
      "     |  \n",
      "     |  st_rdev\n",
      "     |      device type (if inode device)\n",
      "     |  \n",
      "     |  st_size\n",
      "     |      total size, in bytes\n",
      "     |  \n",
      "     |  st_uid\n",
      "     |      user ID of owner\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  n_fields = 22\n",
      "     |  \n",
      "     |  n_sequence_fields = 10\n",
      "     |  \n",
      "     |  n_unnamed_fields = 3\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __getnewargs__(self, /)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class statvfs_result(builtins.tuple)\n",
      "     |  statvfs_result(iterable=(), /)\n",
      "     |  \n",
      "     |  statvfs_result: Result from statvfs or fstatvfs.\n",
      "     |  \n",
      "     |  This object may be accessed either as a tuple of\n",
      "     |    (bsize, frsize, blocks, bfree, bavail, files, ffree, favail, flag, namemax),\n",
      "     |  or via the attributes f_bsize, f_frsize, f_blocks, f_bfree, and so on.\n",
      "     |  \n",
      "     |  See os.statvfs for more information.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      statvfs_result\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  f_bavail\n",
      "     |  \n",
      "     |  f_bfree\n",
      "     |  \n",
      "     |  f_blocks\n",
      "     |  \n",
      "     |  f_bsize\n",
      "     |  \n",
      "     |  f_favail\n",
      "     |  \n",
      "     |  f_ffree\n",
      "     |  \n",
      "     |  f_files\n",
      "     |  \n",
      "     |  f_flag\n",
      "     |  \n",
      "     |  f_frsize\n",
      "     |  \n",
      "     |  f_fsid\n",
      "     |  \n",
      "     |  f_namemax\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  n_fields = 11\n",
      "     |  \n",
      "     |  n_sequence_fields = 10\n",
      "     |  \n",
      "     |  n_unnamed_fields = 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __getnewargs__(self, /)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class terminal_size(builtins.tuple)\n",
      "     |  terminal_size(iterable=(), /)\n",
      "     |  \n",
      "     |  A tuple of (columns, lines) for holding terminal window size\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      terminal_size\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  columns\n",
      "     |      width of the terminal window in characters\n",
      "     |  \n",
      "     |  lines\n",
      "     |      height of the terminal window in characters\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  n_fields = 2\n",
      "     |  \n",
      "     |  n_sequence_fields = 2\n",
      "     |  \n",
      "     |  n_unnamed_fields = 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __getnewargs__(self, /)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class times_result(builtins.tuple)\n",
      "     |  times_result(iterable=(), /)\n",
      "     |  \n",
      "     |  times_result: Result from os.times().\n",
      "     |  \n",
      "     |  This object may be accessed either as a tuple of\n",
      "     |    (user, system, children_user, children_system, elapsed),\n",
      "     |  or via the attributes user, system, children_user, children_system,\n",
      "     |  and elapsed.\n",
      "     |  \n",
      "     |  See os.times for more information.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      times_result\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  children_system\n",
      "     |      system time of children\n",
      "     |  \n",
      "     |  children_user\n",
      "     |      user time of children\n",
      "     |  \n",
      "     |  elapsed\n",
      "     |      elapsed time since an arbitrary point in the past\n",
      "     |  \n",
      "     |  system\n",
      "     |      system time\n",
      "     |  \n",
      "     |  user\n",
      "     |      user time\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  n_fields = 5\n",
      "     |  \n",
      "     |  n_sequence_fields = 5\n",
      "     |  \n",
      "     |  n_unnamed_fields = 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __getnewargs__(self, /)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class uname_result(builtins.tuple)\n",
      "     |  uname_result(iterable=(), /)\n",
      "     |  \n",
      "     |  uname_result: Result from os.uname().\n",
      "     |  \n",
      "     |  This object may be accessed either as a tuple of\n",
      "     |    (sysname, nodename, release, version, machine),\n",
      "     |  or via the attributes sysname, nodename, release, version, and machine.\n",
      "     |  \n",
      "     |  See os.uname for more information.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      uname_result\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  machine\n",
      "     |      hardware identifier\n",
      "     |  \n",
      "     |  nodename\n",
      "     |      name of machine on network (implementation-defined)\n",
      "     |  \n",
      "     |  release\n",
      "     |      operating system release\n",
      "     |  \n",
      "     |  sysname\n",
      "     |      operating system name\n",
      "     |  \n",
      "     |  version\n",
      "     |      operating system version\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  n_fields = 5\n",
      "     |  \n",
      "     |  n_sequence_fields = 5\n",
      "     |  \n",
      "     |  n_unnamed_fields = 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __getnewargs__(self, /)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "\n",
      "FUNCTIONS\n",
      "    WCOREDUMP(status, /)\n",
      "        Return True if the process returning status was dumped to a core file.\n",
      "    \n",
      "    WEXITSTATUS(status)\n",
      "        Return the process return code from status.\n",
      "    \n",
      "    WIFCONTINUED(status)\n",
      "        Return True if a particular process was continued from a job control stop.\n",
      "        \n",
      "        Return True if the process returning status was continued from a\n",
      "        job control stop.\n",
      "    \n",
      "    WIFEXITED(status)\n",
      "        Return True if the process returning status exited via the exit() system call.\n",
      "    \n",
      "    WIFSIGNALED(status)\n",
      "        Return True if the process returning status was terminated by a signal.\n",
      "    \n",
      "    WIFSTOPPED(status)\n",
      "        Return True if the process returning status was stopped.\n",
      "    \n",
      "    WSTOPSIG(status)\n",
      "        Return the signal that stopped the process that provided the status value.\n",
      "    \n",
      "    WTERMSIG(status)\n",
      "        Return the signal that terminated the process that provided the status value.\n",
      "    \n",
      "    _exit(status)\n",
      "        Exit to the system with specified status, without normal exit processing.\n",
      "    \n",
      "    abort()\n",
      "        Abort the interpreter immediately.\n",
      "        \n",
      "        This function 'dumps core' or otherwise fails in the hardest way possible\n",
      "        on the hosting operating system.  This function never returns.\n",
      "    \n",
      "    access(path, mode, *, dir_fd=None, effective_ids=False, follow_symlinks=True)\n",
      "        Use the real uid/gid to test for access to a path.\n",
      "        \n",
      "          path\n",
      "            Path to be tested; can be string, bytes, or a path-like object.\n",
      "          mode\n",
      "            Operating-system mode bitfield.  Can be F_OK to test existence,\n",
      "            or the inclusive-OR of R_OK, W_OK, and X_OK.\n",
      "          dir_fd\n",
      "            If not None, it should be a file descriptor open to a directory,\n",
      "            and path should be relative; path will then be relative to that\n",
      "            directory.\n",
      "          effective_ids\n",
      "            If True, access will use the effective uid/gid instead of\n",
      "            the real uid/gid.\n",
      "          follow_symlinks\n",
      "            If False, and the last element of the path is a symbolic link,\n",
      "            access will examine the symbolic link itself instead of the file\n",
      "            the link points to.\n",
      "        \n",
      "        dir_fd, effective_ids, and follow_symlinks may not be implemented\n",
      "          on your platform.  If they are unavailable, using them will raise a\n",
      "          NotImplementedError.\n",
      "        \n",
      "        Note that most operations will use the effective uid/gid, therefore this\n",
      "          routine can be used in a suid/sgid environment to test if the invoking user\n",
      "          has the specified access to the path.\n",
      "    \n",
      "    chdir(path)\n",
      "        Change the current working directory to the specified path.\n",
      "        \n",
      "        path may always be specified as a string.\n",
      "        On some platforms, path may also be specified as an open file descriptor.\n",
      "          If this functionality is unavailable, using it raises an exception.\n",
      "    \n",
      "    chflags(path, flags, follow_symlinks=True)\n",
      "        Set file flags.\n",
      "        \n",
      "        If follow_symlinks is False, and the last element of the path is a symbolic\n",
      "          link, chflags will change flags on the symbolic link itself instead of the\n",
      "          file the link points to.\n",
      "        follow_symlinks may not be implemented on your platform.  If it is\n",
      "        unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    chmod(path, mode, *, dir_fd=None, follow_symlinks=True)\n",
      "        Change the access permissions of a file.\n",
      "        \n",
      "          path\n",
      "            Path to be modified.  May always be specified as a str, bytes, or a path-like object.\n",
      "            On some platforms, path may also be specified as an open file descriptor.\n",
      "            If this functionality is unavailable, using it raises an exception.\n",
      "          mode\n",
      "            Operating-system mode bitfield.\n",
      "          dir_fd\n",
      "            If not None, it should be a file descriptor open to a directory,\n",
      "            and path should be relative; path will then be relative to that\n",
      "            directory.\n",
      "          follow_symlinks\n",
      "            If False, and the last element of the path is a symbolic link,\n",
      "            chmod will modify the symbolic link itself instead of the file\n",
      "            the link points to.\n",
      "        \n",
      "        It is an error to use dir_fd or follow_symlinks when specifying path as\n",
      "          an open file descriptor.\n",
      "        dir_fd and follow_symlinks may not be implemented on your platform.\n",
      "          If they are unavailable, using them will raise a NotImplementedError.\n",
      "    \n",
      "    chown(path, uid, gid, *, dir_fd=None, follow_symlinks=True)\n",
      "        Change the owner and group id of path to the numeric uid and gid.\\\n",
      "        \n",
      "          path\n",
      "            Path to be examined; can be string, bytes, a path-like object, or open-file-descriptor int.\n",
      "          dir_fd\n",
      "            If not None, it should be a file descriptor open to a directory,\n",
      "            and path should be relative; path will then be relative to that\n",
      "            directory.\n",
      "          follow_symlinks\n",
      "            If False, and the last element of the path is a symbolic link,\n",
      "            stat will examine the symbolic link itself instead of the file\n",
      "            the link points to.\n",
      "        \n",
      "        path may always be specified as a string.\n",
      "        On some platforms, path may also be specified as an open file descriptor.\n",
      "          If this functionality is unavailable, using it raises an exception.\n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        If follow_symlinks is False, and the last element of the path is a symbolic\n",
      "          link, chown will modify the symbolic link itself instead of the file the\n",
      "          link points to.\n",
      "        It is an error to use dir_fd or follow_symlinks when specifying path as\n",
      "          an open file descriptor.\n",
      "        dir_fd and follow_symlinks may not be implemented on your platform.\n",
      "          If they are unavailable, using them will raise a NotImplementedError.\n",
      "    \n",
      "    chroot(path)\n",
      "        Change root directory to path.\n",
      "    \n",
      "    close(fd)\n",
      "        Close a file descriptor.\n",
      "    \n",
      "    closerange(fd_low, fd_high, /)\n",
      "        Closes all file descriptors in [fd_low, fd_high), ignoring errors.\n",
      "    \n",
      "    confstr(name, /)\n",
      "        Return a string-valued system configuration variable.\n",
      "    \n",
      "    cpu_count()\n",
      "        Return the number of CPUs in the system; return None if indeterminable.\n",
      "        \n",
      "        This number is not equivalent to the number of CPUs the current process can\n",
      "        use.  The number of usable CPUs can be obtained with\n",
      "        ``len(os.sched_getaffinity(0))``\n",
      "    \n",
      "    ctermid()\n",
      "        Return the name of the controlling terminal for this process.\n",
      "    \n",
      "    device_encoding(fd)\n",
      "        Return a string describing the encoding of a terminal's file descriptor.\n",
      "        \n",
      "        The file descriptor must be attached to a terminal.\n",
      "        If the device is not a terminal, return None.\n",
      "    \n",
      "    dup(fd, /)\n",
      "        Return a duplicate of a file descriptor.\n",
      "    \n",
      "    dup2(fd, fd2, inheritable=True)\n",
      "        Duplicate file descriptor.\n",
      "    \n",
      "    execl(file, *args)\n",
      "        execl(file, *args)\n",
      "        \n",
      "        Execute the executable file with argument list args, replacing the\n",
      "        current process.\n",
      "    \n",
      "    execle(file, *args)\n",
      "        execle(file, *args, env)\n",
      "        \n",
      "        Execute the executable file with argument list args and\n",
      "        environment env, replacing the current process.\n",
      "    \n",
      "    execlp(file, *args)\n",
      "        execlp(file, *args)\n",
      "        \n",
      "        Execute the executable file (which is searched for along $PATH)\n",
      "        with argument list args, replacing the current process.\n",
      "    \n",
      "    execlpe(file, *args)\n",
      "        execlpe(file, *args, env)\n",
      "        \n",
      "        Execute the executable file (which is searched for along $PATH)\n",
      "        with argument list args and environment env, replacing the current\n",
      "        process.\n",
      "    \n",
      "    execv(path, argv, /)\n",
      "        Execute an executable path with arguments, replacing current process.\n",
      "        \n",
      "        path\n",
      "          Path of executable file.\n",
      "        argv\n",
      "          Tuple or list of strings.\n",
      "    \n",
      "    execve(path, argv, env)\n",
      "        Execute an executable path with arguments, replacing current process.\n",
      "        \n",
      "        path\n",
      "          Path of executable file.\n",
      "        argv\n",
      "          Tuple or list of strings.\n",
      "        env\n",
      "          Dictionary of strings mapping to strings.\n",
      "    \n",
      "    execvp(file, args)\n",
      "        execvp(file, args)\n",
      "        \n",
      "        Execute the executable file (which is searched for along $PATH)\n",
      "        with argument list args, replacing the current process.\n",
      "        args may be a list or tuple of strings.\n",
      "    \n",
      "    execvpe(file, args, env)\n",
      "        execvpe(file, args, env)\n",
      "        \n",
      "        Execute the executable file (which is searched for along $PATH)\n",
      "        with argument list args and environment env , replacing the\n",
      "        current process.\n",
      "        args may be a list or tuple of strings.\n",
      "    \n",
      "    fchdir(fd)\n",
      "        Change to the directory of the given file descriptor.\n",
      "        \n",
      "        fd must be opened on a directory, not a file.\n",
      "        Equivalent to os.chdir(fd).\n",
      "    \n",
      "    fchmod(fd, mode)\n",
      "        Change the access permissions of the file given by file descriptor fd.\n",
      "        \n",
      "        Equivalent to os.chmod(fd, mode).\n",
      "    \n",
      "    fchown(fd, uid, gid)\n",
      "        Change the owner and group id of the file specified by file descriptor.\n",
      "        \n",
      "        Equivalent to os.chown(fd, uid, gid).\n",
      "    \n",
      "    fdopen(fd, *args, **kwargs)\n",
      "        # Supply os.fdopen()\n",
      "    \n",
      "    fork()\n",
      "        Fork a child process.\n",
      "        \n",
      "        Return 0 to child process and PID of child to parent process.\n",
      "    \n",
      "    forkpty()\n",
      "        Fork a new process with a new pseudo-terminal as controlling tty.\n",
      "        \n",
      "        Returns a tuple of (pid, master_fd).\n",
      "        Like fork(), return pid of 0 to the child process,\n",
      "        and pid of child to the parent process.\n",
      "        To both, return fd of newly opened pseudo-terminal.\n",
      "    \n",
      "    fpathconf(fd, name, /)\n",
      "        Return the configuration limit name for the file descriptor fd.\n",
      "        \n",
      "        If there is no limit, return -1.\n",
      "    \n",
      "    fsdecode(filename)\n",
      "        Decode filename (an os.PathLike, bytes, or str) from the filesystem\n",
      "        encoding with 'surrogateescape' error handler, return str unchanged. On\n",
      "        Windows, use 'strict' error handler if the file system encoding is\n",
      "        'mbcs' (which is the default encoding).\n",
      "    \n",
      "    fsencode(filename)\n",
      "        Encode filename (an os.PathLike, bytes, or str) to the filesystem\n",
      "        encoding with 'surrogateescape' error handler, return bytes unchanged.\n",
      "        On Windows, use 'strict' error handler if the file system encoding is\n",
      "        'mbcs' (which is the default encoding).\n",
      "    \n",
      "    fspath(path)\n",
      "        Return the file system path representation of the object.\n",
      "        \n",
      "        If the object is str or bytes, then allow it to pass through as-is. If the\n",
      "        object defines __fspath__(), then return the result of that method. All other\n",
      "        types raise a TypeError.\n",
      "    \n",
      "    fstat(fd)\n",
      "        Perform a stat system call on the given file descriptor.\n",
      "        \n",
      "        Like stat(), but for an open file descriptor.\n",
      "        Equivalent to os.stat(fd).\n",
      "    \n",
      "    fstatvfs(fd, /)\n",
      "        Perform an fstatvfs system call on the given fd.\n",
      "        \n",
      "        Equivalent to statvfs(fd).\n",
      "    \n",
      "    fsync(fd)\n",
      "        Force write of fd to disk.\n",
      "    \n",
      "    ftruncate(fd, length, /)\n",
      "        Truncate a file, specified by file descriptor, to a specific length.\n",
      "    \n",
      "    fwalk(top='.', topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=None)\n",
      "        Directory tree generator.\n",
      "        \n",
      "        This behaves exactly like walk(), except that it yields a 4-tuple\n",
      "        \n",
      "            dirpath, dirnames, filenames, dirfd\n",
      "        \n",
      "        `dirpath`, `dirnames` and `filenames` are identical to walk() output,\n",
      "        and `dirfd` is a file descriptor referring to the directory `dirpath`.\n",
      "        \n",
      "        The advantage of fwalk() over walk() is that it's safe against symlink\n",
      "        races (when follow_symlinks is False).\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and top should be relative; top will then be relative to that directory.\n",
      "          (dir_fd is always supported for fwalk.)\n",
      "        \n",
      "        Caution:\n",
      "        Since fwalk() yields file descriptors, those are only valid until the\n",
      "        next iteration step, so you should dup() them if you want to keep them\n",
      "        for a longer period.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        import os\n",
      "        for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):\n",
      "            print(root, \"consumes\", end=\"\")\n",
      "            print(sum([os.stat(name, dir_fd=rootfd).st_size for name in files]),\n",
      "                  end=\"\")\n",
      "            print(\"bytes in\", len(files), \"non-directory files\")\n",
      "            if 'CVS' in dirs:\n",
      "                dirs.remove('CVS')  # don't visit CVS directories\n",
      "    \n",
      "    get_blocking(...)\n",
      "        get_blocking(fd) -> bool\n",
      "        \n",
      "        Get the blocking mode of the file descriptor:\n",
      "        False if the O_NONBLOCK flag is set, True if the flag is cleared.\n",
      "    \n",
      "    get_exec_path(env=None)\n",
      "        Returns the sequence of directories that will be searched for the\n",
      "        named executable (similar to a shell) when launching a process.\n",
      "        \n",
      "        *env* must be an environment variable dict or None.  If *env* is None,\n",
      "        os.environ will be used.\n",
      "    \n",
      "    get_inheritable(fd, /)\n",
      "        Get the close-on-exe flag of the specified file descriptor.\n",
      "    \n",
      "    get_terminal_size(...)\n",
      "        Return the size of the terminal window as (columns, lines).\n",
      "        \n",
      "        The optional argument fd (default standard output) specifies\n",
      "        which file descriptor should be queried.\n",
      "        \n",
      "        If the file descriptor is not connected to a terminal, an OSError\n",
      "        is thrown.\n",
      "        \n",
      "        This function will only be defined if an implementation is\n",
      "        available for this system.\n",
      "        \n",
      "        shutil.get_terminal_size is the high-level function which should \n",
      "        normally be used, os.get_terminal_size is the low-level implementation.\n",
      "    \n",
      "    getcwd()\n",
      "        Return a unicode string representing the current working directory.\n",
      "    \n",
      "    getcwdb()\n",
      "        Return a bytes string representing the current working directory.\n",
      "    \n",
      "    getegid()\n",
      "        Return the current process's effective group id.\n",
      "    \n",
      "    getenv(key, default=None)\n",
      "        Get an environment variable, return None if it doesn't exist.\n",
      "        The optional second argument can specify an alternate default.\n",
      "        key, default and the result are str.\n",
      "    \n",
      "    getenvb(key, default=None)\n",
      "        Get an environment variable, return None if it doesn't exist.\n",
      "        The optional second argument can specify an alternate default.\n",
      "        key, default and the result are bytes.\n",
      "    \n",
      "    geteuid()\n",
      "        Return the current process's effective user id.\n",
      "    \n",
      "    getgid()\n",
      "        Return the current process's group id.\n",
      "    \n",
      "    getgrouplist(...)\n",
      "        getgrouplist(user, group) -> list of groups to which a user belongs\n",
      "        \n",
      "        Returns a list of groups to which a user belongs.\n",
      "        \n",
      "            user: username to lookup\n",
      "            group: base group id of the user\n",
      "    \n",
      "    getgroups()\n",
      "        Return list of supplemental group IDs for the process.\n",
      "    \n",
      "    getloadavg()\n",
      "        Return average recent system load information.\n",
      "        \n",
      "        Return the number of processes in the system run queue averaged over\n",
      "        the last 1, 5, and 15 minutes as a tuple of three floats.\n",
      "        Raises OSError if the load average was unobtainable.\n",
      "    \n",
      "    getlogin()\n",
      "        Return the actual login name.\n",
      "    \n",
      "    getpgid(pid)\n",
      "        Call the system call getpgid(), and return the result.\n",
      "    \n",
      "    getpgrp()\n",
      "        Return the current process group id.\n",
      "    \n",
      "    getpid()\n",
      "        Return the current process id.\n",
      "    \n",
      "    getppid()\n",
      "        Return the parent's process id.\n",
      "        \n",
      "        If the parent process has already exited, Windows machines will still\n",
      "        return its id; others systems will return the id of the 'init' process (1).\n",
      "    \n",
      "    getpriority(which, who)\n",
      "        Return program scheduling priority.\n",
      "    \n",
      "    getsid(pid, /)\n",
      "        Call the system call getsid(pid) and return the result.\n",
      "    \n",
      "    getuid()\n",
      "        Return the current process's user id.\n",
      "    \n",
      "    initgroups(...)\n",
      "        initgroups(username, gid) -> None\n",
      "        \n",
      "        Call the system initgroups() to initialize the group access list with all of\n",
      "        the groups of which the specified username is a member, plus the specified\n",
      "        group id.\n",
      "    \n",
      "    isatty(fd, /)\n",
      "        Return True if the fd is connected to a terminal.\n",
      "        \n",
      "        Return True if the file descriptor is an open file descriptor\n",
      "        connected to the slave end of a terminal.\n",
      "    \n",
      "    kill(pid, signal, /)\n",
      "        Kill a process with a signal.\n",
      "    \n",
      "    killpg(pgid, signal, /)\n",
      "        Kill a process group with a signal.\n",
      "    \n",
      "    lchflags(path, flags)\n",
      "        Set file flags.\n",
      "        \n",
      "        This function will not follow symbolic links.\n",
      "        Equivalent to chflags(path, flags, follow_symlinks=False).\n",
      "    \n",
      "    lchmod(path, mode)\n",
      "        Change the access permissions of a file, without following symbolic links.\n",
      "        \n",
      "        If path is a symlink, this affects the link itself rather than the target.\n",
      "        Equivalent to chmod(path, mode, follow_symlinks=False).\"\n",
      "    \n",
      "    lchown(path, uid, gid)\n",
      "        Change the owner and group id of path to the numeric uid and gid.\n",
      "        \n",
      "        This function will not follow symbolic links.\n",
      "        Equivalent to os.chown(path, uid, gid, follow_symlinks=False).\n",
      "    \n",
      "    link(src, dst, *, src_dir_fd=None, dst_dir_fd=None, follow_symlinks=True)\n",
      "        Create a hard link to a file.\n",
      "        \n",
      "        If either src_dir_fd or dst_dir_fd is not None, it should be a file\n",
      "          descriptor open to a directory, and the respective path string (src or dst)\n",
      "          should be relative; the path will then be relative to that directory.\n",
      "        If follow_symlinks is False, and the last element of src is a symbolic\n",
      "          link, link will create a link to the symbolic link itself instead of the\n",
      "          file the link points to.\n",
      "        src_dir_fd, dst_dir_fd, and follow_symlinks may not be implemented on your\n",
      "          platform.  If they are unavailable, using them will raise a\n",
      "          NotImplementedError.\n",
      "    \n",
      "    listdir(path=None)\n",
      "        Return a list containing the names of the files in the directory.\n",
      "        \n",
      "        path can be specified as either str, bytes, or a path-like object.  If path is bytes,\n",
      "          the filenames returned will also be bytes; in all other circumstances\n",
      "          the filenames returned will be str.\n",
      "        If path is None, uses the path='.'.\n",
      "        On some platforms, path may also be specified as an open file descriptor;\\\n",
      "          the file descriptor must refer to a directory.\n",
      "          If this functionality is unavailable, using it raises NotImplementedError.\n",
      "        \n",
      "        The list is in arbitrary order.  It does not include the special\n",
      "        entries '.' and '..' even if they are present in the directory.\n",
      "    \n",
      "    lockf(fd, command, length, /)\n",
      "        Apply, test or remove a POSIX lock on an open file descriptor.\n",
      "        \n",
      "        fd\n",
      "          An open file descriptor.\n",
      "        command\n",
      "          One of F_LOCK, F_TLOCK, F_ULOCK or F_TEST.\n",
      "        length\n",
      "          The number of bytes to lock, starting at the current position.\n",
      "    \n",
      "    lseek(fd, position, how, /)\n",
      "        Set the position of a file descriptor.  Return the new position.\n",
      "        \n",
      "        Return the new cursor position in number of bytes\n",
      "        relative to the beginning of the file.\n",
      "    \n",
      "    lstat(path, *, dir_fd=None)\n",
      "        Perform a stat system call on the given path, without following symbolic links.\n",
      "        \n",
      "        Like stat(), but do not follow symbolic links.\n",
      "        Equivalent to stat(path, follow_symlinks=False).\n",
      "    \n",
      "    major(device, /)\n",
      "        Extracts a device major number from a raw device number.\n",
      "    \n",
      "    makedev(major, minor, /)\n",
      "        Composes a raw device number from the major and minor device numbers.\n",
      "    \n",
      "    makedirs(name, mode=511, exist_ok=False)\n",
      "        makedirs(name [, mode=0o777][, exist_ok=False])\n",
      "        \n",
      "        Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n",
      "        mkdir, except that any intermediate path segment (not just the rightmost)\n",
      "        will be created if it does not exist. If the target directory already\n",
      "        exists, raise an OSError if exist_ok is False. Otherwise no exception is\n",
      "        raised.  This is recursive.\n",
      "    \n",
      "    minor(device, /)\n",
      "        Extracts a device minor number from a raw device number.\n",
      "    \n",
      "    mkdir(path, mode=511, *, dir_fd=None)\n",
      "        Create a directory.\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        dir_fd may not be implemented on your platform.\n",
      "          If it is unavailable, using it will raise a NotImplementedError.\n",
      "        \n",
      "        The mode argument is ignored on Windows.\n",
      "    \n",
      "    mkfifo(path, mode=438, *, dir_fd=None)\n",
      "        Create a \"fifo\" (a POSIX named pipe).\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        dir_fd may not be implemented on your platform.\n",
      "          If it is unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    mknod(path, mode=384, device=0, *, dir_fd=None)\n",
      "        Create a node in the file system.\n",
      "        \n",
      "        Create a node in the file system (file, device special file or named pipe)\n",
      "        at path.  mode specifies both the permissions to use and the\n",
      "        type of node to be created, being combined (bitwise OR) with one of\n",
      "        S_IFREG, S_IFCHR, S_IFBLK, and S_IFIFO.  If S_IFCHR or S_IFBLK is set on mode,\n",
      "        device defines the newly created device special file (probably using\n",
      "        os.makedev()).  Otherwise device is ignored.\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        dir_fd may not be implemented on your platform.\n",
      "          If it is unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    nice(increment, /)\n",
      "        Add increment to the priority of process and return the new priority.\n",
      "    \n",
      "    open(path, flags, mode=511, *, dir_fd=None)\n",
      "        Open a file for low level IO.  Returns a file descriptor (integer).\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        dir_fd may not be implemented on your platform.\n",
      "          If it is unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    openpty()\n",
      "        Open a pseudo-terminal.\n",
      "        \n",
      "        Return a tuple of (master_fd, slave_fd) containing open file descriptors\n",
      "        for both the master and slave ends.\n",
      "    \n",
      "    pathconf(path, name)\n",
      "        Return the configuration limit name for the file or directory path.\n",
      "        \n",
      "        If there is no limit, return -1.\n",
      "        On some platforms, path may also be specified as an open file descriptor.\n",
      "          If this functionality is unavailable, using it raises an exception.\n",
      "    \n",
      "    pipe()\n",
      "        Create a pipe.\n",
      "        \n",
      "        Returns a tuple of two file descriptors:\n",
      "          (read_fd, write_fd)\n",
      "    \n",
      "    popen(cmd, mode='r', buffering=-1)\n",
      "        # Supply os.popen()\n",
      "    \n",
      "    pread(fd, length, offset, /)\n",
      "        Read a number of bytes from a file descriptor starting at a particular offset.\n",
      "        \n",
      "        Read length bytes from file descriptor fd, starting at offset bytes from\n",
      "        the beginning of the file.  The file offset remains unchanged.\n",
      "    \n",
      "    putenv(name, value, /)\n",
      "        Change or add an environment variable.\n",
      "    \n",
      "    pwrite(fd, buffer, offset, /)\n",
      "        Write bytes to a file descriptor starting at a particular offset.\n",
      "        \n",
      "        Write buffer to fd, starting at offset bytes from the beginning of\n",
      "        the file.  Returns the number of bytes writte.  Does not change the\n",
      "        current file offset.\n",
      "    \n",
      "    read(fd, length, /)\n",
      "        Read from a file descriptor.  Returns a bytes object.\n",
      "    \n",
      "    readlink(...)\n",
      "        readlink(path, *, dir_fd=None) -> path\n",
      "        \n",
      "        Return a string representing the path to which the symbolic link points.\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        dir_fd may not be implemented on your platform.\n",
      "          If it is unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    readv(fd, buffers, /)\n",
      "        Read from a file descriptor fd into an iterable of buffers.\n",
      "        \n",
      "        The buffers should be mutable buffers accepting bytes.\n",
      "        readv will transfer data into each buffer until it is full\n",
      "        and then move on to the next buffer in the sequence to hold\n",
      "        the rest of the data.\n",
      "        \n",
      "        readv returns the total number of bytes read,\n",
      "        which may be less than the total capacity of all the buffers.\n",
      "    \n",
      "    register_at_fork(*, before=None, after_in_child=None, after_in_parent=None)\n",
      "        Register callables to be called when forking a new process.\n",
      "        \n",
      "          before\n",
      "            A callable to be called in the parent before the fork() syscall.\n",
      "          after_in_child\n",
      "            A callable to be called in the child after fork().\n",
      "          after_in_parent\n",
      "            A callable to be called in the parent after fork().\n",
      "        \n",
      "        'before' callbacks are called in reverse order.\n",
      "        'after_in_child' and 'after_in_parent' callbacks are called in order.\n",
      "    \n",
      "    remove(path, *, dir_fd=None)\n",
      "        Remove a file (same as unlink()).\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        dir_fd may not be implemented on your platform.\n",
      "          If it is unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    removedirs(name)\n",
      "        removedirs(name)\n",
      "        \n",
      "        Super-rmdir; remove a leaf directory and all empty intermediate\n",
      "        ones.  Works like rmdir except that, if the leaf directory is\n",
      "        successfully removed, directories corresponding to rightmost path\n",
      "        segments will be pruned away until either the whole path is\n",
      "        consumed or an error occurs.  Errors during this latter phase are\n",
      "        ignored -- they generally mean that a directory was not empty.\n",
      "    \n",
      "    rename(src, dst, *, src_dir_fd=None, dst_dir_fd=None)\n",
      "        Rename a file or directory.\n",
      "        \n",
      "        If either src_dir_fd or dst_dir_fd is not None, it should be a file\n",
      "          descriptor open to a directory, and the respective path string (src or dst)\n",
      "          should be relative; the path will then be relative to that directory.\n",
      "        src_dir_fd and dst_dir_fd, may not be implemented on your platform.\n",
      "          If they are unavailable, using them will raise a NotImplementedError.\n",
      "    \n",
      "    renames(old, new)\n",
      "        renames(old, new)\n",
      "        \n",
      "        Super-rename; create directories as necessary and delete any left\n",
      "        empty.  Works like rename, except creation of any intermediate\n",
      "        directories needed to make the new pathname good is attempted\n",
      "        first.  After the rename, directories corresponding to rightmost\n",
      "        path segments of the old name will be pruned until either the\n",
      "        whole path is consumed or a nonempty directory is found.\n",
      "        \n",
      "        Note: this function can fail with the new directory structure made\n",
      "        if you lack permissions needed to unlink the leaf directory or\n",
      "        file.\n",
      "    \n",
      "    replace(src, dst, *, src_dir_fd=None, dst_dir_fd=None)\n",
      "        Rename a file or directory, overwriting the destination.\n",
      "        \n",
      "        If either src_dir_fd or dst_dir_fd is not None, it should be a file\n",
      "          descriptor open to a directory, and the respective path string (src or dst)\n",
      "          should be relative; the path will then be relative to that directory.\n",
      "        src_dir_fd and dst_dir_fd, may not be implemented on your platform.\n",
      "          If they are unavailable, using them will raise a NotImplementedError.\n",
      "    \n",
      "    rmdir(path, *, dir_fd=None)\n",
      "        Remove a directory.\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        dir_fd may not be implemented on your platform.\n",
      "          If it is unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    scandir(path=None)\n",
      "        Return an iterator of DirEntry objects for given path.\n",
      "        \n",
      "        path can be specified as either str, bytes, or a path-like object.  If path\n",
      "        is bytes, the names of yielded DirEntry objects will also be bytes; in\n",
      "        all other circumstances they will be str.\n",
      "        \n",
      "        If path is None, uses the path='.'.\n",
      "    \n",
      "    sched_get_priority_max(policy)\n",
      "        Get the maximum scheduling priority for policy.\n",
      "    \n",
      "    sched_get_priority_min(policy)\n",
      "        Get the minimum scheduling priority for policy.\n",
      "    \n",
      "    sched_yield()\n",
      "        Voluntarily relinquish the CPU.\n",
      "    \n",
      "    sendfile(...)\n",
      "        sendfile(out, in, offset, count) -> byteswritten\n",
      "        sendfile(out, in, offset, count[, headers][, trailers], flags=0)\n",
      "                    -> byteswritten\n",
      "        Copy count bytes from file descriptor in to file descriptor out.\n",
      "    \n",
      "    set_blocking(...)\n",
      "        set_blocking(fd, blocking)\n",
      "        \n",
      "        Set the blocking mode of the specified file descriptor.\n",
      "        Set the O_NONBLOCK flag if blocking is False,\n",
      "        clear the O_NONBLOCK flag otherwise.\n",
      "    \n",
      "    set_inheritable(fd, inheritable, /)\n",
      "        Set the inheritable flag of the specified file descriptor.\n",
      "    \n",
      "    setegid(egid, /)\n",
      "        Set the current process's effective group id.\n",
      "    \n",
      "    seteuid(euid, /)\n",
      "        Set the current process's effective user id.\n",
      "    \n",
      "    setgid(gid, /)\n",
      "        Set the current process's group id.\n",
      "    \n",
      "    setgroups(groups, /)\n",
      "        Set the groups of the current process to list.\n",
      "    \n",
      "    setpgid(pid, pgrp, /)\n",
      "        Call the system call setpgid(pid, pgrp).\n",
      "    \n",
      "    setpgrp()\n",
      "        Make the current process the leader of its process group.\n",
      "    \n",
      "    setpriority(which, who, priority)\n",
      "        Set program scheduling priority.\n",
      "    \n",
      "    setregid(rgid, egid, /)\n",
      "        Set the current process's real and effective group ids.\n",
      "    \n",
      "    setreuid(ruid, euid, /)\n",
      "        Set the current process's real and effective user ids.\n",
      "    \n",
      "    setsid()\n",
      "        Call the system call setsid().\n",
      "    \n",
      "    setuid(uid, /)\n",
      "        Set the current process's user id.\n",
      "    \n",
      "    spawnl(mode, file, *args)\n",
      "        spawnl(mode, file, *args) -> integer\n",
      "        \n",
      "        Execute file with arguments from args in a subprocess.\n",
      "        If mode == P_NOWAIT return the pid of the process.\n",
      "        If mode == P_WAIT return the process's exit code if it exits normally;\n",
      "        otherwise return -SIG, where SIG is the signal that killed it.\n",
      "    \n",
      "    spawnle(mode, file, *args)\n",
      "        spawnle(mode, file, *args, env) -> integer\n",
      "        \n",
      "        Execute file with arguments from args in a subprocess with the\n",
      "        supplied environment.\n",
      "        If mode == P_NOWAIT return the pid of the process.\n",
      "        If mode == P_WAIT return the process's exit code if it exits normally;\n",
      "        otherwise return -SIG, where SIG is the signal that killed it.\n",
      "    \n",
      "    spawnlp(mode, file, *args)\n",
      "        spawnlp(mode, file, *args) -> integer\n",
      "        \n",
      "        Execute file (which is looked for along $PATH) with arguments from\n",
      "        args in a subprocess with the supplied environment.\n",
      "        If mode == P_NOWAIT return the pid of the process.\n",
      "        If mode == P_WAIT return the process's exit code if it exits normally;\n",
      "        otherwise return -SIG, where SIG is the signal that killed it.\n",
      "    \n",
      "    spawnlpe(mode, file, *args)\n",
      "        spawnlpe(mode, file, *args, env) -> integer\n",
      "        \n",
      "        Execute file (which is looked for along $PATH) with arguments from\n",
      "        args in a subprocess with the supplied environment.\n",
      "        If mode == P_NOWAIT return the pid of the process.\n",
      "        If mode == P_WAIT return the process's exit code if it exits normally;\n",
      "        otherwise return -SIG, where SIG is the signal that killed it.\n",
      "    \n",
      "    spawnv(mode, file, args)\n",
      "        spawnv(mode, file, args) -> integer\n",
      "        \n",
      "        Execute file with arguments from args in a subprocess.\n",
      "        If mode == P_NOWAIT return the pid of the process.\n",
      "        If mode == P_WAIT return the process's exit code if it exits normally;\n",
      "        otherwise return -SIG, where SIG is the signal that killed it.\n",
      "    \n",
      "    spawnve(mode, file, args, env)\n",
      "        spawnve(mode, file, args, env) -> integer\n",
      "        \n",
      "        Execute file with arguments from args in a subprocess with the\n",
      "        specified environment.\n",
      "        If mode == P_NOWAIT return the pid of the process.\n",
      "        If mode == P_WAIT return the process's exit code if it exits normally;\n",
      "        otherwise return -SIG, where SIG is the signal that killed it.\n",
      "    \n",
      "    spawnvp(mode, file, args)\n",
      "        spawnvp(mode, file, args) -> integer\n",
      "        \n",
      "        Execute file (which is looked for along $PATH) with arguments from\n",
      "        args in a subprocess.\n",
      "        If mode == P_NOWAIT return the pid of the process.\n",
      "        If mode == P_WAIT return the process's exit code if it exits normally;\n",
      "        otherwise return -SIG, where SIG is the signal that killed it.\n",
      "    \n",
      "    spawnvpe(mode, file, args, env)\n",
      "        spawnvpe(mode, file, args, env) -> integer\n",
      "        \n",
      "        Execute file (which is looked for along $PATH) with arguments from\n",
      "        args in a subprocess with the supplied environment.\n",
      "        If mode == P_NOWAIT return the pid of the process.\n",
      "        If mode == P_WAIT return the process's exit code if it exits normally;\n",
      "        otherwise return -SIG, where SIG is the signal that killed it.\n",
      "    \n",
      "    stat(path, *, dir_fd=None, follow_symlinks=True)\n",
      "        Perform a stat system call on the given path.\n",
      "        \n",
      "          path\n",
      "            Path to be examined; can be string, bytes, a path-like object or\n",
      "            open-file-descriptor int.\n",
      "          dir_fd\n",
      "            If not None, it should be a file descriptor open to a directory,\n",
      "            and path should be a relative string; path will then be relative to\n",
      "            that directory.\n",
      "          follow_symlinks\n",
      "            If False, and the last element of the path is a symbolic link,\n",
      "            stat will examine the symbolic link itself instead of the file\n",
      "            the link points to.\n",
      "        \n",
      "        dir_fd and follow_symlinks may not be implemented\n",
      "          on your platform.  If they are unavailable, using them will raise a\n",
      "          NotImplementedError.\n",
      "        \n",
      "        It's an error to use dir_fd or follow_symlinks when specifying path as\n",
      "          an open file descriptor.\n",
      "    \n",
      "    statvfs(path)\n",
      "        Perform a statvfs system call on the given path.\n",
      "        \n",
      "        path may always be specified as a string.\n",
      "        On some platforms, path may also be specified as an open file descriptor.\n",
      "          If this functionality is unavailable, using it raises an exception.\n",
      "    \n",
      "    strerror(code, /)\n",
      "        Translate an error code to a message string.\n",
      "    \n",
      "    symlink(src, dst, target_is_directory=False, *, dir_fd=None)\n",
      "        Create a symbolic link pointing to src named dst.\n",
      "        \n",
      "        target_is_directory is required on Windows if the target is to be\n",
      "          interpreted as a directory.  (On Windows, symlink requires\n",
      "          Windows 6.0 or greater, and raises a NotImplementedError otherwise.)\n",
      "          target_is_directory is ignored on non-Windows platforms.\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        dir_fd may not be implemented on your platform.\n",
      "          If it is unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    sync()\n",
      "        Force write of everything to disk.\n",
      "    \n",
      "    sysconf(name, /)\n",
      "        Return an integer-valued system configuration variable.\n",
      "    \n",
      "    system(command)\n",
      "        Execute the command in a subshell.\n",
      "    \n",
      "    tcgetpgrp(fd, /)\n",
      "        Return the process group associated with the terminal specified by fd.\n",
      "    \n",
      "    tcsetpgrp(fd, pgid, /)\n",
      "        Set the process group associated with the terminal specified by fd.\n",
      "    \n",
      "    times()\n",
      "        Return a collection containing process timing information.\n",
      "        \n",
      "        The object returned behaves like a named tuple with these fields:\n",
      "          (utime, stime, cutime, cstime, elapsed_time)\n",
      "        All fields are floating point numbers.\n",
      "    \n",
      "    truncate(path, length)\n",
      "        Truncate a file, specified by path, to a specific length.\n",
      "        \n",
      "        On some platforms, path may also be specified as an open file descriptor.\n",
      "          If this functionality is unavailable, using it raises an exception.\n",
      "    \n",
      "    ttyname(fd, /)\n",
      "        Return the name of the terminal device connected to 'fd'.\n",
      "        \n",
      "        fd\n",
      "          Integer file descriptor handle.\n",
      "    \n",
      "    umask(mask, /)\n",
      "        Set the current numeric umask and return the previous umask.\n",
      "    \n",
      "    uname()\n",
      "        Return an object identifying the current operating system.\n",
      "        \n",
      "        The object behaves like a named tuple with the following fields:\n",
      "          (sysname, nodename, release, version, machine)\n",
      "    \n",
      "    unlink(path, *, dir_fd=None)\n",
      "        Remove a file (same as remove()).\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        dir_fd may not be implemented on your platform.\n",
      "          If it is unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    unsetenv(name, /)\n",
      "        Delete an environment variable.\n",
      "    \n",
      "    urandom(size, /)\n",
      "        Return a bytes object containing random bytes suitable for cryptographic use.\n",
      "    \n",
      "    utime(path, times=None, *, ns=None, dir_fd=None, follow_symlinks=True)\n",
      "        Set the access and modified time of path.\n",
      "        \n",
      "        path may always be specified as a string.\n",
      "        On some platforms, path may also be specified as an open file descriptor.\n",
      "          If this functionality is unavailable, using it raises an exception.\n",
      "        \n",
      "        If times is not None, it must be a tuple (atime, mtime);\n",
      "            atime and mtime should be expressed as float seconds since the epoch.\n",
      "        If ns is specified, it must be a tuple (atime_ns, mtime_ns);\n",
      "            atime_ns and mtime_ns should be expressed as integer nanoseconds\n",
      "            since the epoch.\n",
      "        If times is None and ns is unspecified, utime uses the current time.\n",
      "        Specifying tuples for both times and ns is an error.\n",
      "        \n",
      "        If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "          and path should be relative; path will then be relative to that directory.\n",
      "        If follow_symlinks is False, and the last element of the path is a symbolic\n",
      "          link, utime will modify the symbolic link itself instead of the file the\n",
      "          link points to.\n",
      "        It is an error to use dir_fd or follow_symlinks when specifying path\n",
      "          as an open file descriptor.\n",
      "        dir_fd and follow_symlinks may not be available on your platform.\n",
      "          If they are unavailable, using them will raise a NotImplementedError.\n",
      "    \n",
      "    wait()\n",
      "        Wait for completion of a child process.\n",
      "        \n",
      "        Returns a tuple of information about the child process:\n",
      "            (pid, status)\n",
      "    \n",
      "    wait3(options)\n",
      "        Wait for completion of a child process.\n",
      "        \n",
      "        Returns a tuple of information about the child process:\n",
      "          (pid, status, rusage)\n",
      "    \n",
      "    wait4(pid, options)\n",
      "        Wait for completion of a specific child process.\n",
      "        \n",
      "        Returns a tuple of information about the child process:\n",
      "          (pid, status, rusage)\n",
      "    \n",
      "    waitpid(pid, options, /)\n",
      "        Wait for completion of a given child process.\n",
      "        \n",
      "        Returns a tuple of information regarding the child process:\n",
      "            (pid, status)\n",
      "        \n",
      "        The options argument is ignored on Windows.\n",
      "    \n",
      "    walk(top, topdown=True, onerror=None, followlinks=False)\n",
      "        Directory tree generator.\n",
      "        \n",
      "        For each directory in the directory tree rooted at top (including top\n",
      "        itself, but excluding '.' and '..'), yields a 3-tuple\n",
      "        \n",
      "            dirpath, dirnames, filenames\n",
      "        \n",
      "        dirpath is a string, the path to the directory.  dirnames is a list of\n",
      "        the names of the subdirectories in dirpath (excluding '.' and '..').\n",
      "        filenames is a list of the names of the non-directory files in dirpath.\n",
      "        Note that the names in the lists are just names, with no path components.\n",
      "        To get a full path (which begins with top) to a file or directory in\n",
      "        dirpath, do os.path.join(dirpath, name).\n",
      "        \n",
      "        If optional arg 'topdown' is true or not specified, the triple for a\n",
      "        directory is generated before the triples for any of its subdirectories\n",
      "        (directories are generated top down).  If topdown is false, the triple\n",
      "        for a directory is generated after the triples for all of its\n",
      "        subdirectories (directories are generated bottom up).\n",
      "        \n",
      "        When topdown is true, the caller can modify the dirnames list in-place\n",
      "        (e.g., via del or slice assignment), and walk will only recurse into the\n",
      "        subdirectories whose names remain in dirnames; this can be used to prune the\n",
      "        search, or to impose a specific order of visiting.  Modifying dirnames when\n",
      "        topdown is false is ineffective, since the directories in dirnames have\n",
      "        already been generated by the time dirnames itself is generated. No matter\n",
      "        the value of topdown, the list of subdirectories is retrieved before the\n",
      "        tuples for the directory and its subdirectories are generated.\n",
      "        \n",
      "        By default errors from the os.scandir() call are ignored.  If\n",
      "        optional arg 'onerror' is specified, it should be a function; it\n",
      "        will be called with one argument, an OSError instance.  It can\n",
      "        report the error to continue with the walk, or raise the exception\n",
      "        to abort the walk.  Note that the filename is available as the\n",
      "        filename attribute of the exception object.\n",
      "        \n",
      "        By default, os.walk does not follow symbolic links to subdirectories on\n",
      "        systems that support them.  In order to get this functionality, set the\n",
      "        optional argument 'followlinks' to true.\n",
      "        \n",
      "        Caution:  if you pass a relative pathname for top, don't change the\n",
      "        current working directory between resumptions of walk.  walk never\n",
      "        changes the current directory, and assumes that the client doesn't\n",
      "        either.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        import os\n",
      "        from os.path import join, getsize\n",
      "        for root, dirs, files in os.walk('python/Lib/email'):\n",
      "            print(root, \"consumes\", end=\"\")\n",
      "            print(sum([getsize(join(root, name)) for name in files]), end=\"\")\n",
      "            print(\"bytes in\", len(files), \"non-directory files\")\n",
      "            if 'CVS' in dirs:\n",
      "                dirs.remove('CVS')  # don't visit CVS directories\n",
      "    \n",
      "    write(fd, data, /)\n",
      "        Write a bytes object to a file descriptor.\n",
      "    \n",
      "    writev(fd, buffers, /)\n",
      "        Iterate over buffers, and write the contents of each to a file descriptor.\n",
      "        \n",
      "        Returns the total number of bytes written.\n",
      "        buffers must be a sequence of bytes-like objects.\n",
      "\n",
      "DATA\n",
      "    CLD_CONTINUED = 6\n",
      "    CLD_DUMPED = 3\n",
      "    CLD_EXITED = 1\n",
      "    CLD_TRAPPED = 4\n",
      "    EX_CANTCREAT = 73\n",
      "    EX_CONFIG = 78\n",
      "    EX_DATAERR = 65\n",
      "    EX_IOERR = 74\n",
      "    EX_NOHOST = 68\n",
      "    EX_NOINPUT = 66\n",
      "    EX_NOPERM = 77\n",
      "    EX_NOUSER = 67\n",
      "    EX_OK = 0\n",
      "    EX_OSERR = 71\n",
      "    EX_OSFILE = 72\n",
      "    EX_PROTOCOL = 76\n",
      "    EX_SOFTWARE = 70\n",
      "    EX_TEMPFAIL = 75\n",
      "    EX_UNAVAILABLE = 69\n",
      "    EX_USAGE = 64\n",
      "    F_LOCK = 1\n",
      "    F_OK = 0\n",
      "    F_TEST = 3\n",
      "    F_TLOCK = 2\n",
      "    F_ULOCK = 0\n",
      "    NGROUPS_MAX = 16\n",
      "    O_ACCMODE = 3\n",
      "    O_APPEND = 8\n",
      "    O_ASYNC = 64\n",
      "    O_CLOEXEC = 16777216\n",
      "    O_CREAT = 512\n",
      "    O_DIRECTORY = 1048576\n",
      "    O_DSYNC = 4194304\n",
      "    O_EXCL = 2048\n",
      "    O_EXLOCK = 32\n",
      "    O_NDELAY = 4\n",
      "    O_NOCTTY = 131072\n",
      "    O_NOFOLLOW = 256\n",
      "    O_NONBLOCK = 4\n",
      "    O_RDONLY = 0\n",
      "    O_RDWR = 2\n",
      "    O_SHLOCK = 16\n",
      "    O_SYNC = 128\n",
      "    O_TRUNC = 1024\n",
      "    O_WRONLY = 1\n",
      "    PRIO_PGRP = 1\n",
      "    PRIO_PROCESS = 0\n",
      "    PRIO_USER = 2\n",
      "    P_ALL = 0\n",
      "    P_NOWAIT = 1\n",
      "    P_NOWAITO = 1\n",
      "    P_PGID = 2\n",
      "    P_PID = 1\n",
      "    P_WAIT = 0\n",
      "    RTLD_GLOBAL = 8\n",
      "    RTLD_LAZY = 1\n",
      "    RTLD_LOCAL = 4\n",
      "    RTLD_NODELETE = 128\n",
      "    RTLD_NOLOAD = 16\n",
      "    RTLD_NOW = 2\n",
      "    R_OK = 4\n",
      "    SCHED_FIFO = 4\n",
      "    SCHED_OTHER = 1\n",
      "    SCHED_RR = 2\n",
      "    SEEK_CUR = 1\n",
      "    SEEK_END = 2\n",
      "    SEEK_SET = 0\n",
      "    ST_NOSUID = 2\n",
      "    ST_RDONLY = 1\n",
      "    TMP_MAX = 308915776\n",
      "    WCONTINUED = 16\n",
      "    WEXITED = 4\n",
      "    WNOHANG = 1\n",
      "    WNOWAIT = 32\n",
      "    WSTOPPED = 8\n",
      "    WUNTRACED = 2\n",
      "    W_OK = 2\n",
      "    X_OK = 1\n",
      "    __all__ = ['altsep', 'curdir', 'pardir', 'sep', 'pathsep', 'linesep', ...\n",
      "    altsep = None\n",
      "    confstr_names = {'CS_PATH': 1, 'CS_XBS5_ILP32_OFF32_CFLAGS': 20, 'CS_X...\n",
      "    curdir = '.'\n",
      "    defpath = '/bin:/usr/bin'\n",
      "    devnull = '/dev/null'\n",
      "    environ = environ({'TERM_SESSION_ID': 'w0t1p0:8A6E58C7-07F...END': 'mo...\n",
      "    environb = environ({b'TERM_SESSION_ID': b'w0t1p0:8A6E58C7-0...ND': b'm...\n",
      "    extsep = '.'\n",
      "    linesep = '\\n'\n",
      "    name = 'posix'\n",
      "    pardir = '..'\n",
      "    pathconf_names = {'PC_ALLOC_SIZE_MIN': 16, 'PC_ASYNC_IO': 17, 'PC_CHOW...\n",
      "    pathsep = ':'\n",
      "    sep = '/'\n",
      "    supports_bytes_environ = True\n",
      "    sysconf_names = {'SC_2_CHAR_TERM': 20, 'SC_2_C_BIND': 18, 'SC_2_C_DEV'...\n",
      "\n",
      "FILE\n",
      "    /Users/yuki/anaconda3/lib/python3.7/os.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "help(os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline Engine\n",
    "We'll be using Zipline's pipeline package to access our data for this project. To use it, we must build a pipeline engine. Run the cell below to build the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors import AverageDollarVolume\n",
    "from zipline.utils.calendars import get_calendar\n",
    "\n",
    "\n",
    "universe = AverageDollarVolume(window_length=120).top(500) \n",
    "trading_calendar = get_calendar('NYSE') \n",
    "bundle_data = bundles.load(project_helper.EOD_BUNDLE_NAME)\n",
    "engine = project_helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "With the pipeline engine built, let's get the stocks at the end of the period in the universe we're using. We'll use these tickers to generate the returns data for the our risk model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_end_date = pd.Timestamp('2016-01-05', tz='UTC')\n",
    "\n",
    "universe_tickers = engine\\\n",
    "    .run_pipeline(\n",
    "        Pipeline(screen=universe),\n",
    "        universe_end_date,\n",
    "        universe_end_date)\\\n",
    "    .index.get_level_values(1)\\\n",
    "    .values.tolist()\n",
    "    \n",
    "universe_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Returns\n",
    "Not that we have our pipeline built, let's access the returns data. We'll start by building a data portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data.data_portal import DataPortal\n",
    "\n",
    "\n",
    "data_portal = DataPortal(\n",
    "    bundle_data.asset_finder,\n",
    "    trading_calendar=trading_calendar,\n",
    "    first_trading_day=bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "    equity_minute_reader=None,\n",
    "    equity_daily_reader=bundle_data.equity_daily_bar_reader,\n",
    "    adjustment_reader=bundle_data.adjustment_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the code easier to read, we've built the helper function `get_pricing` to get the pricing from the data portal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pricing(data_portal, trading_calendar, assets, start_date, end_date, field='close'):\n",
    "    end_dt = pd.Timestamp(end_date.strftime('%Y-%m-%d'), tz='UTC', offset='C')\n",
    "    start_dt = pd.Timestamp(start_date.strftime('%Y-%m-%d'), tz='UTC', offset='C')\n",
    "\n",
    "    end_loc = trading_calendar.closes.index.get_loc(end_dt)\n",
    "    start_loc = trading_calendar.closes.index.get_loc(start_dt)\n",
    "\n",
    "    return data_portal.get_history_window(\n",
    "        assets=assets,\n",
    "        end_dt=end_dt,\n",
    "        bar_count=end_loc - start_loc,\n",
    "        frequency='1d',\n",
    "        field=field,\n",
    "        data_frequency='daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's get returns data for our risk model using the `get_pricing` function. For this model, we'll be looking back to 5 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_year_returns = \\\n",
    "    get_pricing(\n",
    "        data_portal,\n",
    "        trading_calendar,\n",
    "        universe_tickers,\n",
    "        universe_end_date - pd.DateOffset(years=5),\n",
    "        universe_end_date)\\\n",
    "    .pct_change()[1:].fillna(0)\n",
    "\n",
    "five_year_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Risk Model\n",
    "It's time to build the risk model. You'll be creating a statistical risk model using PCA. So, the first thing is building the PCA model.\n",
    "## Fit PCA\n",
    "Implement `fit_pca` to fit a PCA model to the returns data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def fit_pca(returns, num_factor_exposures, svd_solver):\n",
    "    \"\"\"\n",
    "    Fit PCA model with returns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    num_factor_exposures : int\n",
    "        Number of factors for PCA\n",
    "    svd_solver: str\n",
    "        The solver to use for the PCA model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pca : PCA\n",
    "        Model fit to returns\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_fit_pca(fit_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's see what the model looks like. First, we'll look at the PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factor_exposures = 20\n",
    "pca = fit_pca(five_year_returns, num_factor_exposures, 'full')\n",
    "\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at the PCA's percent of variance explained by each factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(num_factor_exposures), pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that the first factor dominates. The precise definition of each factor in a latent model is unknown, however we can guess at the likely interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Betas\n",
    "Implement `factor_betas` to get the factor betas from the PCA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_betas(pca, factor_beta_indices, factor_beta_columns):\n",
    "    \"\"\"\n",
    "    Get the factor betas from the PCA model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pca : PCA\n",
    "        Model fit to returns\n",
    "    factor_beta_indices : 1 dimensional Ndarray\n",
    "        Factor beta indices\n",
    "    factor_beta_columns : 1 dimensional Ndarray\n",
    "        Factor beta columns\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    factor_betas : DataFrame\n",
    "        Factor betas\n",
    "    \"\"\"\n",
    "    assert len(factor_beta_indices.shape) == 1\n",
    "    assert len(factor_beta_columns.shape) == 1\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_factor_betas(factor_betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's view the factor betas from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model = {}\n",
    "risk_model['factor_betas'] = factor_betas(pca, five_year_returns.columns.values, np.arange(num_factor_exposures))\n",
    "\n",
    "risk_model['factor_betas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Returns\n",
    "Implement `factor_returns` to get the factor returns from the PCA model using the returns data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_returns(pca, returns, factor_return_indices, factor_return_columns):\n",
    "    \"\"\"\n",
    "    Get the factor returns from the PCA model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pca : PCA\n",
    "        Model fit to returns\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    factor_return_indices : 1 dimensional Ndarray\n",
    "        Factor return indices\n",
    "    factor_return_columns : 1 dimensional Ndarray\n",
    "        Factor return columns\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    factor_returns : DataFrame\n",
    "        Factor returns\n",
    "    \"\"\"\n",
    "    assert len(factor_return_indices.shape) == 1\n",
    "    assert len(factor_return_columns.shape) == 1\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_factor_returns(factor_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's see what these factor returns looks like over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model['factor_returns'] = factor_returns(\n",
    "    pca,\n",
    "    five_year_returns,\n",
    "    five_year_returns.index,\n",
    "    np.arange(num_factor_exposures))\n",
    "\n",
    "risk_model['factor_returns'].cumsum().plot(legend=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Covariance Matrix\n",
    "Implement `factor_cov_matrix` to get the factor covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_cov_matrix(factor_returns, ann_factor):\n",
    "    \"\"\"\n",
    "    Get the factor covariance matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    factor_returns : DataFrame\n",
    "        Factor returns\n",
    "    ann_factor : int\n",
    "        Annualization factor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    factor_cov_matrix : 2 dimensional Ndarray\n",
    "        Factor covariance matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_factor_cov_matrix(factor_cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_factor = 252\n",
    "risk_model['factor_cov_matrix'] = factor_cov_matrix(risk_model['factor_returns'], ann_factor)\n",
    "\n",
    "risk_model['factor_cov_matrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idiosyncratic Variance Matrix\n",
    "Implement `idiosyncratic_var_matrix` to get the idiosyncratic variance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idiosyncratic_var_matrix(returns, factor_returns, factor_betas, ann_factor):\n",
    "    \"\"\"\n",
    "    Get the idiosyncratic variance matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    factor_returns : DataFrame\n",
    "        Factor returns\n",
    "    factor_betas : DataFrame\n",
    "        Factor betas\n",
    "    ann_factor : int\n",
    "        Annualization factor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    idiosyncratic_var_matrix : DataFrame\n",
    "        Idiosyncratic variance matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_idiosyncratic_var_matrix(idiosyncratic_var_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model['idiosyncratic_var_matrix'] = idiosyncratic_var_matrix(five_year_returns, risk_model['factor_returns'], risk_model['factor_betas'], ann_factor)\n",
    "\n",
    "risk_model['idiosyncratic_var_matrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idiosyncratic Variance Vector\n",
    "Implement `idiosyncratic_var_vector` to get the idiosyncratic variance Vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idiosyncratic_var_vector(returns, idiosyncratic_var_matrix):\n",
    "    \"\"\"\n",
    "    Get the idiosyncratic variance vector\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    idiosyncratic_var_matrix : DataFrame\n",
    "        Idiosyncratic variance matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    idiosyncratic_var_vector : DataFrame\n",
    "        Idiosyncratic variance Vector\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_idiosyncratic_var_vector(idiosyncratic_var_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model['idiosyncratic_var_vector'] = idiosyncratic_var_vector(five_year_returns, risk_model['idiosyncratic_var_matrix'])\n",
    "\n",
    "risk_model['idiosyncratic_var_vector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the Risk Model\n",
    "Using the data we calculated in the risk model, implement `predict_portfolio_risk` to predict the portfolio risk using the formula $ \\sqrt{X^{T}(BFB^{T} + S)X} $ where:\n",
    "- $ X $ is the portfolio weights\n",
    "- $ B $ is the factor betas\n",
    "- $ F $ is the factor covariance matrix\n",
    "- $ S $ is the idiosyncratic variance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_portfolio_risk(factor_betas, factor_cov_matrix, idiosyncratic_var_matrix, weights):\n",
    "    \"\"\"\n",
    "    Get the predicted portfolio risk\n",
    "    \n",
    "    Formula for predicted portfolio risk is sqrt(X.T(BFB.T + S)X) where:\n",
    "      X is the portfolio weights\n",
    "      B is the factor betas\n",
    "      F is the factor covariance matrix\n",
    "      S is the idiosyncratic variance matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    factor_betas : DataFrame\n",
    "        Factor betas\n",
    "    factor_cov_matrix : 2 dimensional Ndarray\n",
    "        Factor covariance matrix\n",
    "    idiosyncratic_var_matrix : DataFrame\n",
    "        Idiosyncratic variance matrix\n",
    "    weights : DataFrame\n",
    "        Portfolio weights\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predicted_portfolio_risk : float\n",
    "        Predicted portfolio risk\n",
    "    \"\"\"\n",
    "    assert len(factor_cov_matrix.shape) == 2\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_predict_portfolio_risk(predict_portfolio_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's see what the portfolio risk would be if we had even weights across all stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = pd.DataFrame(np.repeat(1/len(universe_tickers), len(universe_tickers)), universe_tickers)\n",
    "\n",
    "predict_portfolio_risk(\n",
    "    risk_model['factor_betas'],\n",
    "    risk_model['factor_cov_matrix'],\n",
    "    risk_model['idiosyncratic_var_matrix'],\n",
    "    all_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Alpha Factors\n",
    "With the profile risk calculated, it's time to start working on the alpha factors. In this project, we'll create the following factors:\n",
    "- Momentum 1 Year Factor\n",
    "- Mean Reversion 5 Day Sector Neutral Factor\n",
    "- Mean Reversion 5 Day Sector Neutral Smoothed Factor\n",
    "- Overnight Sentiment Factor\n",
    "- Overnight Sentiment Smoothed Factor\n",
    "\n",
    "## Momentum 1 Year Factor\n",
    "Each factor will have a hypothesis that goes with it. For this factor, it is \"Higher past 12-month (252 days) returns are proportional to future return.\" Using that hypothesis, we've generated this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.factors import Returns\n",
    "\n",
    "def momentum_1yr(window_length, universe, sector):\n",
    "    return Returns(window_length=window_length, mask=universe) \\\n",
    "        .demean(groupby=sector) \\\n",
    "        .rank() \\\n",
    "        .zscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Reversion 5 Day Sector Neutral Factor\n",
    "Now it's time for you to implement `mean_reversion_5day_sector_neutral` using the hypothesis \"Short-term outperformers(underperformers) compared to their sector will revert.\" Use the returns data from `universe`, demean using the sector data to partition, rank, then converted to a zscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reversion_5day_sector_neutral(window_length, universe, sector):\n",
    "    \"\"\"\n",
    "    Generate the mean reversion 5 day sector neutral factor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    window_length : int\n",
    "        Returns window length\n",
    "    universe : Zipline Filter\n",
    "        Universe of stocks filter\n",
    "    sector : Zipline Classifier\n",
    "        Sector classifier\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    factor : Zipline Factor\n",
    "        Mean reversion 5 day sector neutral factor\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_mean_reversion_5day_sector_neutral(mean_reversion_5day_sector_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's see what some of the factor data looks like. For calculating factors, we'll be looking back 2 years.\n",
    "\n",
    "**Note:** _Going back 2 years falls on a day when the market is closed. Pipeline package doesn't handle start or end dates that don't fall on days when the market is open. To fix this, we went back 2 extra days to fall on the next day when the market is open._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_start_date = universe_end_date - pd.DateOffset(years=2, days=2)\n",
    "sector = project_helper.Sector()\n",
    "window_length = 5\n",
    "\n",
    "pipeline = Pipeline(screen=universe)\n",
    "pipeline.add(\n",
    "    mean_reversion_5day_sector_neutral(window_length, universe, sector),\n",
    "    'Mean_Reversion_5Day_Sector_Neutral')\n",
    "engine.run_pipeline(pipeline, factor_start_date, universe_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Reversion 5 Day Sector Neutral Smoothed Factor\n",
    "Taking the output of the previous factor, let's create a smoothed version. Implement `mean_reversion_5day_sector_neutral_smoothed` to generate a mean reversion 5 fay sector neutral smoothed factor. Call the `mean_reversion_5day_sector_neutral` function to get the unsmoothed factor, then use `SimpleMovingAverage` function to smooth it. You'll have to apply rank and zscore again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.factors import SimpleMovingAverage\n",
    "\n",
    "def mean_reversion_5day_sector_neutral_smoothed(window_length, universe, sector):\n",
    "    \"\"\"\n",
    "    Generate the mean reversion 5 day sector neutral smoothed factor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    window_length : int\n",
    "        Returns window length\n",
    "    universe : Zipline Filter\n",
    "        Universe of stocks filter\n",
    "    sector : Zipline Classifier\n",
    "        Sector classifier\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    factor : Zipline Factor\n",
    "        Mean reversion 5 day sector neutral smoothed factor\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_mean_reversion_5day_sector_neutral_smoothed(mean_reversion_5day_sector_neutral_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's see what some of the smoothed data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(screen=universe)\n",
    "pipeline.add(\n",
    "    mean_reversion_5day_sector_neutral_smoothed(5, universe, sector),\n",
    "    'Mean_Reversion_5Day_Sector_Neutral_Smoothed')\n",
    "engine.run_pipeline(pipeline, factor_start_date, universe_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overnight Sentiment Factor\n",
    "For this factor, were using the hypothesis from the paper [_Overnight Returns and Firm-Specific Investor Sentiment_](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2554010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.data import USEquityPricing\n",
    "\n",
    "\n",
    "class CTO(Returns):\n",
    "    \"\"\"\n",
    "    Computes the overnight return, per hypothesis from\n",
    "    https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2554010\n",
    "    \"\"\"\n",
    "    inputs = [USEquityPricing.open, USEquityPricing.close]\n",
    "    \n",
    "    def compute(self, today, assets, out, opens, closes):\n",
    "        \"\"\"\n",
    "        The opens and closes matrix is 2 rows x N assets, with the most recent at the bottom.\n",
    "        As such, opens[-1] is the most recent open, and closes[0] is the earlier close\n",
    "        \"\"\"\n",
    "        out[:] = (opens[-1] - closes[0]) / closes[0]\n",
    "\n",
    "        \n",
    "class TrailingOvernightReturns(Returns):\n",
    "    \"\"\"\n",
    "    Sum of trailing 1m O/N returns\n",
    "    \"\"\"\n",
    "    window_safe = True\n",
    "    \n",
    "    def compute(self, today, asset_ids, out, cto):\n",
    "        out[:] = np.nansum(cto, axis=0)\n",
    "\n",
    "        \n",
    "def overnight_sentiment(cto_window_length, trail_overnight_returns_window_length, universe):\n",
    "    cto_out = CTO(mask=universe, window_length=cto_window_length)\n",
    "    return TrailingOvernightReturns(inputs=[cto_out], window_length=trail_overnight_returns_window_length) \\\n",
    "        .rank() \\\n",
    "        .zscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overnight Sentiment Smoothed Factor\n",
    "Just like the factor you implemented, we'll also smooth this factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overnight_sentiment_smoothed(cto_window_length, trail_overnight_returns_window_length, universe):\n",
    "    unsmoothed_factor = overnight_sentiment(cto_window_length, trail_overnight_returns_window_length, universe)\n",
    "    return SimpleMovingAverage(inputs=[unsmoothed_factor], window_length=trail_overnight_returns_window_length) \\\n",
    "        .rank() \\\n",
    "        .zscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the Factors to a single Pipeline\n",
    "With all the factor implementations done, let's add them to a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = AverageDollarVolume(window_length=120).top(500)\n",
    "sector = project_helper.Sector()\n",
    "\n",
    "pipeline = Pipeline(screen=universe)\n",
    "pipeline.add(\n",
    "    momentum_1yr(252, universe, sector),\n",
    "    'Momentum_1YR')\n",
    "pipeline.add(\n",
    "    mean_reversion_5day_sector_neutral(5, universe, sector),\n",
    "    'Mean_Reversion_5Day_Sector_Neutral')\n",
    "pipeline.add(\n",
    "    mean_reversion_5day_sector_neutral_smoothed(5, universe, sector),\n",
    "    'Mean_Reversion_5Day_Sector_Neutral_Smoothed')\n",
    "pipeline.add(\n",
    "    overnight_sentiment(2, 5, universe),\n",
    "    'Overnight_Sentiment')\n",
    "pipeline.add(\n",
    "    overnight_sentiment_smoothed(2, 5, universe),\n",
    "    'Overnight_Sentiment_Smoothed')\n",
    "all_factors = engine.run_pipeline(pipeline, factor_start_date, universe_end_date)\n",
    "\n",
    "all_factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Alpha Factors\n",
    "*Note:* _We're evaluating the alpha factors using delay of 1_\n",
    "## Get Pricing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphalens as al\n",
    "\n",
    "assets = all_factors.index.levels[1].values.tolist()\n",
    "pricing = get_pricing(\n",
    "    data_portal,\n",
    "    trading_calendar,\n",
    "    assets,\n",
    "    factor_start_date,\n",
    "    universe_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format alpha factors and pricing for Alphalens\n",
    "In order to use a lot of the alphalens functions, we need to aligned the indices and convert the time to unix timestamp. In this next cell, we'll do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_factor_data = {\n",
    "    factor: al.utils.get_clean_factor_and_forward_returns(factor=factor_data, prices=pricing, periods=[1])\n",
    "    for factor, factor_data in all_factors.iteritems()}\n",
    "\n",
    "unixt_factor_data = {\n",
    "    factor: factor_data.set_index(pd.MultiIndex.from_tuples(\n",
    "        [(x.timestamp(), y) for x, y in factor_data.index.values],\n",
    "        names=['date', 'asset']))\n",
    "    for factor, factor_data in clean_factor_data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Analysis\n",
    "### Factor Returns\n",
    "Let's view the factor returns over time. We should be seeing it generally move up and to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_factor_returns = pd.DataFrame()\n",
    "\n",
    "for factor, factor_data in clean_factor_data.items():\n",
    "    ls_factor_returns[factor] = al.performance.factor_returns(factor_data).iloc[:, 0]\n",
    "\n",
    "(1+ls_factor_returns).cumprod().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basis Points Per Day per Quantile\n",
    "It is not enough to look just at the factor weighted return. A good alpha is also monotonic in quantiles. Let's looks the basis points for the factor returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr_factor_returns = pd.DataFrame()\n",
    "\n",
    "for factor, factor_data in unixt_factor_data.items():\n",
    "    qr_factor_returns[factor] = al.performance.mean_return_by_quantile(factor_data)[0].iloc[:, 0]\n",
    "\n",
    "(10000*qr_factor_returns).plot.bar(\n",
    "    subplots=True,\n",
    "    sharey=True,\n",
    "    layout=(4,2),\n",
    "    figsize=(14, 14),\n",
    "    legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe?\n",
    "\n",
    "- None of these alphas are **strictly monotonic**; this should lead you to question why this is? Further research and refinement of the alphas needs to be done. What is it about these alphas that leads to the highest ranking stocks in all alphas except MR 5D smoothed to *not* perform the best.\n",
    "- The majority of the return is coming from the **short side** in all these alphas. The negative return in quintile 1 is very large in all alphas. This could also a cause for concern becuase when you short stocks, you need to locate the short; shorts can be expensive or not available at all.\n",
    "- If you look at the magnitude of the return spread (i.e., Q1 minus Q5), we are working with daily returns in the 0.03%, i.e., **3 basis points**, neighborhood *before all transaction costs, shorting costs, etc.*. Assuming 252 days in a year, that's 7.56% return annualized. Transaction costs may cut this in half. As such, it should be clear that these alphas can only survive in an institutional setting and that leverage will likely need to be applied in order to achieve an attractive return.\n",
    "\n",
    "## Turnover Analysis\n",
    "\n",
    "Without doing a full and formal backtest, we can analyze how stable the alphas are over time. Stability in this sense means that from period to period, the alpha ranks do not change much. Since trading is costly, we always prefer, all other things being equal, that the ranks do not change significantly per period. We can measure this with the **factor rank autocorrelation (FRA)**.\n",
    "\n",
    "[alphalens.performance.factor_rank_autocorrelation](https://quantopian.github.io/alphalens/alphalens.html?highlight=factor_rank_autocorrelation#alphalens.performance.factor_rank_autocorrelation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_FRA = pd.DataFrame()\n",
    "\n",
    "for factor, factor_data in unixt_factor_data.items():\n",
    "    ls_FRA[factor] = al.performance.factor_rank_autocorrelation(factor_data)\n",
    "\n",
    "ls_FRA.plot(title=\"Factor Rank Autocorrelation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpe Ratio of the Alphas\n",
    "\n",
    "The last analysis we'll do on the factors will be sharpe ratio. Implement `sharpe_ratio` to calculate the sharpe ratio of factor returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(factor_returns, annualization_factor):\n",
    "    \"\"\"\n",
    "    Get the sharpe ratio for each factor for the entire period\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    factor_returns : DataFrame\n",
    "        Factor returns for each factor and date\n",
    "    annualization_factor: float\n",
    "        Annualization Factor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sharpe_ratio : Pandas Series of floats\n",
    "        Sharpe ratio\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_sharpe_ratio(sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's see what the sharpe ratio for the factors are. Generally, a Sharpe Ratio of near 1.0 or higher is an acceptable single alpha for this universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_annualization_factor = np.sqrt(252)\n",
    "sharpe_ratio(ls_factor_returns, daily_annualization_factor).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What do you think would happen if we smooth the momentum factor? Would the performance increase, decrease, or no major change? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_#TODO: Put Answer In this Cell_\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Combined Alpha Vector\n",
    "\n",
    "To use these alphas in a portfolio, we need to combine them somehow so we get a single score per stock. This is a area where machine learning can be very helpful. In this module, however, we will take the simplest approach of combination: simply averaging the scores from each alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_factors = all_factors.columns[[1, 2, 4]]\n",
    "print('Selected Factors: {}'.format(', '.join(selected_factors)))\n",
    "\n",
    "all_factors['alpha_vector'] = all_factors[selected_factors].mean(axis=1)\n",
    "alphas = all_factors[['alpha_vector']]\n",
    "alpha_vector = alphas.loc[all_factors.index.get_level_values(0)[-1]]\n",
    "alpha_vector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Portfolio Constrained by Risk Model\n",
    "You have an alpha model and a risk model. Let's find a portfolio that trades as close as possible to the alpha model but limiting risk as measured by the risk model. You'll be building thie optimizer for this portfolio. To help you out. we have provided you with an abstract class called `AbstractOptimalHoldings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class AbstractOptimalHoldings(ABC):    \n",
    "    @abstractmethod\n",
    "    def _get_obj(self, weights, alpha_vector):\n",
    "        \"\"\"\n",
    "        Get the objective function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights : CVXPY Variable\n",
    "            Portfolio weights\n",
    "        alpha_vector : DataFrame\n",
    "            Alpha vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        objective : CVXPY Objective\n",
    "            Objective function\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_constraints(self, weights, factor_betas, risk):\n",
    "        \"\"\"\n",
    "        Get the constraints\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights : CVXPY Variable\n",
    "            Portfolio weights\n",
    "        factor_betas : 2 dimensional Ndarray\n",
    "            Factor betas\n",
    "        risk: CVXPY Atom\n",
    "            Predicted variance of the portfolio returns\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        constraints : List of CVXPY Constraint\n",
    "            Constraints\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _get_risk(self, weights, factor_betas, alpha_vector_index, factor_cov_matrix, idiosyncratic_var_vector):\n",
    "        f = factor_betas.loc[alpha_vector_index].values.T * weights\n",
    "        X = factor_cov_matrix\n",
    "        S = np.diag(idiosyncratic_var_vector.loc[alpha_vector_index].values.flatten())\n",
    "\n",
    "        return cvx.quad_form(f, X) + cvx.quad_form(weights, S)\n",
    "    \n",
    "    def find(self, alpha_vector, factor_betas, factor_cov_matrix, idiosyncratic_var_vector):\n",
    "        weights = cvx.Variable(len(alpha_vector))\n",
    "        risk = self._get_risk(weights, factor_betas, alpha_vector.index, factor_cov_matrix, idiosyncratic_var_vector)\n",
    "        \n",
    "        obj = self._get_obj(weights, alpha_vector)\n",
    "        constraints = self._get_constraints(weights, factor_betas.loc[alpha_vector.index].values, risk)\n",
    "        \n",
    "        prob = cvx.Problem(obj, constraints)\n",
    "        prob.solve(max_iters=500)\n",
    "\n",
    "        optimal_weights = np.asarray(weights.value).flatten()\n",
    "        \n",
    "        return pd.DataFrame(data=optimal_weights, index=alpha_vector.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective and Constraints\n",
    "Using this class as a base class, you'll implement the `OptimalHoldings` class. There's two functions that need to be implemented in this class, the `_get_obj` and `_get_constraints` functions.\n",
    "\n",
    "The `_get_obj` function should return an CVXPY objective function that maximizes $ \\alpha^T * x \\\\ $, where $ x $ is the portfolio weights and $ \\alpha $ is the alpha vector.\n",
    "\n",
    "The `_get_constraints` function should return a list of the following constraints:\n",
    "- $ r \\leq risk_{\\text{cap}}^2 \\\\ $\n",
    "- $ B^T * x \\preceq factor_{\\text{max}} \\\\ $\n",
    "- $ B^T * x \\succeq factor_{\\text{min}} \\\\ $\n",
    "- $ x^T\\mathbb{1} = 0 \\\\ $\n",
    "- $ \\|x\\|_1 \\leq 1 \\\\ $\n",
    "- $ x \\succeq weights_{\\text{min}} \\\\ $\n",
    "- $ x \\preceq weights_{\\text{max}} $\n",
    "\n",
    "Where $ x $ is the portfolio weights, $ B $ is the factor betas, and $ r $ is the portfolio risk\n",
    "\n",
    "The first constraint is that the predicted risk be less than some maximum limit. The second and third constraints are on the maximum and minimum portfolio factor exposures. The fourth constraint is the \"market neutral constraint: the sum of the weights must be zero. The fifth constraint is the leverage constraint: the sum of the absolute value of the weights must be less than or equal to 1.0. The last are some minimum and maximum limits on individual holdings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalHoldings(AbstractOptimalHoldings):\n",
    "    def _get_obj(self, weights, alpha_vector):\n",
    "        \"\"\"\n",
    "        Get the objective function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights : CVXPY Variable\n",
    "            Portfolio weights\n",
    "        alpha_vector : DataFrame\n",
    "            Alpha vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        objective : CVXPY Objective\n",
    "            Objective function\n",
    "        \"\"\"\n",
    "        assert(len(alpha_vector.columns) == 1)\n",
    "\n",
    "        #TODO: Implement function\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _get_constraints(self, weights, factor_betas, risk):\n",
    "        \"\"\"\n",
    "        Get the constraints\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights : CVXPY Variable\n",
    "            Portfolio weights\n",
    "        factor_betas : 2 dimensional Ndarray\n",
    "            Factor betas\n",
    "        risk: CVXPY Atom\n",
    "            Predicted variance of the portfolio returns\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        constraints : List of CVXPY Constraint\n",
    "            Constraints\n",
    "        \"\"\"\n",
    "        assert(len(factor_betas.shape) == 2)\n",
    "        \n",
    "        #TODO: Implement function\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def __init__(self, risk_cap=0.05, factor_max=10.0, factor_min=-10.0, weights_max=0.55, weights_min=-0.55):\n",
    "        self.risk_cap=risk_cap\n",
    "        self.factor_max=factor_max\n",
    "        self.factor_min=factor_min\n",
    "        self.weights_max=weights_max\n",
    "        self.weights_min=weights_min\n",
    "\n",
    "\n",
    "project_tests.test_optimal_holdings_get_obj(OptimalHoldings)\n",
    "project_tests.test_optimal_holdings_get_constraints(OptimalHoldings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "With the `OptimalHoldings` class implemented, let's see the weights it generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights = OptimalHoldings().find(alpha_vector, risk_model['factor_betas'], risk_model['factor_cov_matrix'], risk_model['idiosyncratic_var_vector'])\n",
    "\n",
    "optimal_weights.plot.bar(legend=None, title='Portfolio % Holdings by Stock')\n",
    "x_axis = plt.axes().get_xaxis()\n",
    "x_axis.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes. It put most of the weight in a few stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_helper.get_factor_exposures(risk_model['factor_betas'], optimal_weights).plot.bar(\n",
    "    title='Portfolio Net Factor Exposures',\n",
    "    legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize with a Regularization Parameter\n",
    "In order to enforce diversification, we'll use regularization in the objective function. We'll create a new class called `OptimalHoldingsRegualization` which gets its constraints from the `OptimalHoldings` class. In this new class, implement the `_get_obj` function to return a CVXPY objective function that maximize $ \\alpha^T * x + \\lambda\\|x\\|_2\\\\ $, where $ x $ is the portfolio weights, $ \\alpha $ is the alpha vector, and $ \\lambda $ is the regularization parameter.\n",
    "\n",
    "**Note:** * $ \\lambda $ is located in `self.lambda_reg`. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalHoldingsRegualization(OptimalHoldings):\n",
    "    def _get_obj(self, weights, alpha_vector):\n",
    "        \"\"\"\n",
    "        Get the objective function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights : CVXPY Variable\n",
    "            Portfolio weights\n",
    "        alpha_vector : DataFrame\n",
    "            Alpha vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        objective : CVXPY Objective\n",
    "            Objective function\n",
    "        \"\"\"\n",
    "        assert(len(alpha_vector.columns) == 1)\n",
    "        \n",
    "        #TODO: Implement function\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def __init__(self, lambda_reg=0.5, risk_cap=0.05, factor_max=10.0, factor_min=-10.0, weights_max=0.55, weights_min=-0.55):\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.risk_cap=risk_cap\n",
    "        self.factor_max=factor_max\n",
    "        self.factor_min=factor_min\n",
    "        self.weights_max=weights_max\n",
    "        self.weights_min=weights_min\n",
    "        \n",
    "\n",
    "project_tests.test_optimal_holdings_regualization_get_obj(OptimalHoldingsRegualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights_1 = OptimalHoldingsRegualization(lambda_reg=5.0).find(alpha_vector, risk_model['factor_betas'], risk_model['factor_cov_matrix'], risk_model['idiosyncratic_var_vector'])\n",
    "\n",
    "optimal_weights_1.plot.bar(legend=None, title='Portfolio % Holdings by Stock')\n",
    "x_axis = plt.axes().get_xaxis()\n",
    "x_axis.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. Well diversified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_helper.get_factor_exposures(risk_model['factor_betas'], optimal_weights_1).plot.bar(\n",
    "    title='Portfolio Net Factor Exposures',\n",
    "    legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize with a Strict Factor Constraints and Target Weighting\n",
    "Another common formulation is to take a predefined target weighting, $x^*$ (e.g., a quantile portfolio), and solve to get as close to that portfolio while respecting portfolio-level constraints. For this next class, `OptimalHoldingsStrictFactor`, you'll implement the `_get_obj` function to minimize on on $ \\|x - x^*\\|_2 $, where $ x $ is the portfolio weights  $ x^* $ is the target weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalHoldingsStrictFactor(OptimalHoldings):\n",
    "    def _get_obj(self, weights, alpha_vector):\n",
    "        \"\"\"\n",
    "        Get the objective function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights : CVXPY Variable\n",
    "            Portfolio weights\n",
    "        alpha_vector : DataFrame\n",
    "            Alpha vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        objective : CVXPY Objective\n",
    "            Objective function\n",
    "        \"\"\"\n",
    "        assert(len(alpha_vector.columns) == 1)\n",
    "        \n",
    "        #TODO: Implement function\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "project_tests.test_optimal_holdings_strict_factor_get_obj(OptimalHoldingsStrictFactor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights_2 = OptimalHoldingsStrictFactor(\n",
    "    weights_max=0.02,\n",
    "    weights_min=-0.02,\n",
    "    risk_cap=0.0015,\n",
    "    factor_max=0.015,\n",
    "    factor_min=-0.015).find(alpha_vector, risk_model['factor_betas'], risk_model['factor_cov_matrix'], risk_model['idiosyncratic_var_vector'])\n",
    "\n",
    "optimal_weights_2.plot.bar(legend=None, title='Portfolio % Holdings by Stock')\n",
    "x_axis = plt.axes().get_xaxis()\n",
    "x_axis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_helper.get_factor_exposures(risk_model['factor_betas'], optimal_weights_2).plot.bar(\n",
    "    title='Portfolio Net Factor Exposures',\n",
    "    legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Now that you're done with the project, it's time to submit it. Click the submit button in the bottom right. One of our reviewers will give you feedback on your project with a pass or not passed grade. You can continue to the next section while you wait for feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
